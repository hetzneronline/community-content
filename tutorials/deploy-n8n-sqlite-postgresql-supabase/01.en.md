---
SPDX-License-Identifier: MIT
path: "/tutorials/deploy-n8n-sqlite-postgresql-supabase"
slug: "deploy-n8n-sqlite-postgresql-supabase"
date: "2025-06-13"
title: "Deploy n8n with SQLite, PostgreSQL, or Supabase"
short_description: "Learn three deployment methods for n8n: lightweight SQLite, scalable PostgreSQL, or managed Supabase."
tags: ["n8n", "PostgreSQL", "Supabase", "SQLite", "Database", "Docker", "Automation"]
author: "Sascha Seniuk"
author_link: "https://github.com/saschaseniuk"
author_img: "https://avatars.githubusercontent.com/u/26901604"
author_description: ""
language: "en"
available_languages: ["en"]
header_img: "header-x"
cta: "cloud"
---

## Introduction

n8n is a powerful workflow automation tool that can be deployed with different database backends depending on your needs. This tutorial covers three deployment methods:

* **SQLite Edition**: Lightweight solution perfect for small projects
* **PostgreSQL Edition**: Robust database for growing teams and higher workloads
* **Supabase Edition**: Managed PostgreSQL service for teams wanting to outsource database administration

Each method offers different benefits in terms of scalability, performance, and maintenance requirements.

**Prerequisites**

* Hetzner Cloud Server
* Ubuntu 20.04 LTS or newer
* Docker and Docker Compose installed
* Basic command-line knowledge
* (Optional) Domain name for accessing n8n

## Method 1 - SQLite Edition (Beginner-Friendly)

SQLite is the default database for n8n. It's perfect for getting started quickly with minimal configuration.

### When to Use SQLite

* Small projects with up to 5,000-10,000 daily workflow executions
* Single-user or small team deployments
* When simplicity is more important than scalability
* Testing and development environments

### Limitations

* Handles 10-15 concurrent workflows maximum
* Database should remain under 5 GB
* Can struggle with simultaneous write operations
* No built-in replication or high availability

### Deploy n8n with SQLite

Create a directory for your n8n installation:

```bash
mkdir ~/n8n-sqlite
cd ~/n8n-sqlite
```

Create a `docker-compose.yml` file:

```yaml
version: '3.8'

services:
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://${N8N_HOST:-localhost}:5678/
      - GENERIC_TIMEZONE=Europe/Berlin
    volumes:
      - n8n_data:/home/node/.n8n
      - ./local-files:/files

volumes:
  n8n_data:
    external: true
```

Create the volume and start n8n:

```bash
docker volume create n8n_data
docker-compose up -d
```

Your n8n instance is now accessible at `http://your-server-ip:5678`.

## Method 2 - PostgreSQL Edition (Production-Ready)

PostgreSQL provides better performance and reliability for production workloads.

### When to Use PostgreSQL

* Projects with up to 50,000 daily workflow executions
* Team environments requiring concurrent access
* When data integrity and reliability are critical
* Need for advanced database features (backups, replication)

### Deploy PostgreSQL

First, create a directory for the PostgreSQL setup:

```bash
mkdir ~/n8n-postgresql
cd ~/n8n-postgresql
```

Create a `docker-compose.yml` file:

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      - POSTGRES_USER=n8n
      - POSTGRES_PASSWORD=n8n_password_change_me
      - POSTGRES_DB=n8n
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U n8n"]
      interval: 10s
      timeout: 5s
      retries: 5

  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://${N8N_HOST:-localhost}:5678/
      - GENERIC_TIMEZONE=Europe/Berlin
      # PostgreSQL configuration
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=postgres
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=n8n
      - DB_POSTGRESDB_USER=n8n
      - DB_POSTGRESDB_PASSWORD=n8n_password_change_me
    volumes:
      - n8n_data:/home/node/.n8n
      - ./local-files:/files
    depends_on:
      postgres:
        condition: service_healthy

volumes:
  n8n_data:
  postgres_data:
```

Start the services:

```bash
docker-compose up -d
```

### PostgreSQL Maintenance

Set up automated backups:

```bash
# Create backup script
cat > backup-postgres.sh << 'EOF'
#!/bin/bash
BACKUP_DIR="./backups"
mkdir -p "$BACKUP_DIR"
docker-compose exec -T postgres pg_dump -U n8n n8n | gzip > "$BACKUP_DIR/n8n-backup-$(date +%Y%m%d-%H%M%S).sql.gz"
# Keep only last 7 days of backups
find "$BACKUP_DIR" -name "n8n-backup-*.sql.gz" -mtime +7 -delete
EOF

chmod +x backup-postgres.sh

# Add to crontab for daily backups at 2 AM
(crontab -l 2>/dev/null; echo "0 2 * * * cd ~/n8n-postgresql && ./backup-postgres.sh") | crontab -
```

## Method 3 - Supabase Edition (Managed Database)

Supabase provides a managed PostgreSQL database, eliminating database administration overhead.

### When to Use Supabase

* Teams wanting to outsource database management
* Projects requiring geographic distribution
* When you need additional features (real-time subscriptions, storage)
* Simplified backup and recovery processes

### Set Up Supabase

1. Create a free account at [supabase.com](https://supabase.com)
2. Create a new project
3. Go to Settings â†’ Database
4. Copy the connection string (URI format)

### Deploy n8n with Supabase

Create a directory for the Supabase setup:

```bash
mkdir ~/n8n-supabase
cd ~/n8n-supabase
```

Create a `docker-compose.yml` file:

```yaml
version: '3.8'

services:
  n8n:
    image: n8nio/n8n:latest
    restart: unless-stopped
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - NODE_ENV=production
      - WEBHOOK_URL=http://${N8N_HOST:-localhost}:5678/
      - GENERIC_TIMEZONE=Europe/Berlin
      # Supabase configuration
      - DB_TYPE=postgresdb
      - DB_POSTGRESDB_HOST=aws-0-eu-central-1.pooler.supabase.com  # Replace with your host
      - DB_POSTGRESDB_PORT=5432
      - DB_POSTGRESDB_DATABASE=postgres
      - DB_POSTGRESDB_USER=postgres.xxxxxxxxxxxx  # Replace with your user
      - DB_POSTGRESDB_PASSWORD=your_supabase_password  # Replace with your password
      - DB_POSTGRESDB_SSL_ENABLED=true
      - DB_POSTGRESDB_SSL_REJECT_UNAUTHORIZED=false
    volumes:
      - n8n_data:/home/node/.n8n
      - ./local-files:/files

volumes:
  n8n_data:
```

Update the environment variables with your Supabase connection details and start:

```bash
docker-compose up -d
```

## Securing Your Deployment

Regardless of the database choice, follow these security practices:

### 1. Use HTTPS with a Reverse Proxy

Install Caddy for automatic HTTPS:

```bash
# Install Caddy
sudo apt install -y debian-keyring debian-archive-keyring apt-transport-https
curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/gpg.key' | sudo gpg --dearmor -o /usr/share/keyrings/caddy-stable-archive-keyring.gpg
curl -1sLf 'https://dl.cloudsmith.io/public/caddy/stable/debian.deb.txt' | sudo tee /etc/apt/sources.list.d/caddy-stable.list
sudo apt update
sudo apt install caddy

# Configure Caddy
sudo tee /etc/caddy/Caddyfile << EOF
n8n.yourdomain.com {
    reverse_proxy localhost:5678
}
EOF

sudo systemctl reload caddy
```

### 2. Enable Authentication

Add these environment variables to your n8n service:

```yaml
environment:
  - N8N_BASIC_AUTH_ACTIVE=true
  - N8N_BASIC_AUTH_USER=admin
  - N8N_BASIC_AUTH_PASSWORD=your_secure_password
```

### 3. Configure Firewall

```bash
# Allow SSH, HTTP, and HTTPS
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable
```

## Performance Comparison

| Feature | SQLite | PostgreSQL | Supabase |
|---------|---------|------------|----------|
| Daily Workflows | 5,000-10,000 | Up to 50,000 | Up to 50,000 |
| Concurrent Workflows | 10-15 | 100+ | 100+ |
| Setup Complexity | Simple | Medium | Medium |
| Maintenance | Minimal | Regular | Managed |
| Backup Strategy | File copy | pg_dump | Automated |
| Cost | Free | Server costs | Free tier + usage |

## Troubleshooting

### Common Issues

1. **n8n won't start**: Check logs with `docker-compose logs n8n`
2. **Database connection errors**: Verify credentials and network connectivity
3. **Performance issues**: Monitor with `docker stats` and consider upgrading

### Monitoring

Add this monitoring stack to any deployment:

```yaml
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
```

## Conclusion

You now have three deployment options for n8n:

* **SQLite**: Start here for simple projects
* **PostgreSQL**: Upgrade when you need more performance
* **Supabase**: Choose for managed database benefits

Start with SQLite and migrate to PostgreSQL or Supabase as your needs grow. Each method provides a solid foundation for workflow automation with n8n.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: [Sascha Seniuk sascha@aiscream.de]

-->