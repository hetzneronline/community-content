---
SPDX-License-Identifier: MIT
path: "/tutorials/gpu-ai-ubuntu-setup"
slug: "gpu-ai-ubuntu-setup"
date: "2025-03-31"
title: "Installation von PyTorch, TensorFlow und JupyterLab unter Ubuntu 24.04 mit GPU-Unterstützung"
short_description: "Lerne, wie du PyTorch, TensorFlow und JupyterLab mit NVIDIA-GPU-Unterstützung in einer Conda-Umgebung unter Ubuntu 24.04 installierst."
tags: ["Ubuntu", "GPU", "PyTorch", "TensorFlow", "JupyterLab", "NVIDIA", "CUDA"]
author: "Jonas Zielke"
author_link: "Jonas-Zielke"
author_img: ""
author_description: "jonas-zielke.de"
language: "de"
available_languages: ["de", "en"]
header_img: "header-4"
cta: "dedicated-gpu"
---

## Einleitung

In diesem Tutorial lernst du, wie du eine leistungsfähige KI-Entwicklungsumgebung unter **Ubuntu 24.04** einrichtest – optimiert für das Training neuronaler Netze mit einer **NVIDIA GPU** Wir verwenden **Miniconda**, um eine Python-Umgebung zu erstellen und installieren darin aktuelle Versionen von **PyTorch**, **TensorFlow** und **JupyterLab** mit voller GPU-Unterstützung.

Dabei richten wir die erforderlichen NVIDIA-Treiber, das CUDA Toolkit und cuDNN ein. Die Anleitung enthält außerdem Best Practices, Tipps zur Fehlerbehebung und Performance-Optimierungen.

## Voraussetzungen
- Server mit ubunut 24.04
- Nvidia GPU
- Administratorrechte (`sudo`)
- GPU-Server (z. B. GEX130 oder GEX44)

---

## Schritt 1: System vorbereiten

System aktualisieren und benötigte Pakete installieren:

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install build-essential wget curl -y
```

---

## Schritt 2: NVIDIA-Treiber installieren

Ubuntu 24.04 bietet das Tool `ubuntu-drivers`, um passende GPU-Treiber automatisch zu erkennen und zu installieren.

1. **Verfügbare Treiber anzeigen:**
   ```bash
   ubuntu-drivers list --gpgpu
   ```

2. **Empfohlenen Treiber installieren:**
   ```bash
   sudo ubuntu-drivers install --gpgpu
   ```

3. **System neu starten:**
   ```bash
   sudo reboot
   ```

4. **Installation überprüfen:**
   ```bash
   nvidia-smi
   ```
   Du solltest die Treiberversion sehen.

---

## Schritt 3: CUDA Toolkit und cuDNN installieren

### CUDA Toolkit installieren:

```bash
sudo apt install -y nvidia-cuda-toolkit
```

Installation überprüfen:
```bash
nvcc --version
```

### cuDNN installieren:

1. Lade cuDNN für CUDA 12.x von der [NVIDIA-Website](https://developer.nvidia.com/cudnn) herunter.
2. Falls du ein `.deb`-Paket hast:

```bash
sudo dpkg -i cudnn-local-repo-ubuntu2404-*.deb
sudo apt update
sudo apt install libcudnn8 libcudnn8-dev
```

> ✅ Überprüfen: `ls /usr/lib/x86_64-linux-gnu/libcudnn*` sollte vorhandene cuDNN-Bibliotheken anzeigen.

---

## Schritt 4: Miniconda installieren

Miniconda herunterladen und installieren:

```bash
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
sh Miniconda3-latest-Linux-x86_64.sh
```

Nach der Installation:
```bash
source ~/.bashrc
```

Erstelle und aktiviere die Conda-Umgebung:
```bash
conda create -n ai_env python=3.10 -y
conda activate ai_env
```

---

## Schritt 5: PyTorch und TensorFlow mit GPU-Support installieren

### PyTorch mit CUDA installieren:

```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
```

### TensorFlow mit CUDA installieren:

```bash
pip install --upgrade pip
pip install "tensorflow[and-cuda]"
```

> ✅ GPU-Unterstützung überprüfen:
```bash
python -c "import torch; print(torch.cuda.is_available())"
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

---

## Schritt 6: JupyterLab installieren

JupyterLab installieren:
```bash
conda install -c conda-forge jupyterlab -y
```

Optional: Umgebung als Jupyter-Kernel registrieren:
```bash
conda install ipykernel -y
python -m ipykernel install --user --name ai_env --display-name "Python (ai_env)"
```

JupyterLab starten:
```bash
jupyter lab
```

---

## Schritt 7: GPU-Beschleunigung testen

### PyTorch-Test:
```python
import torch
x = torch.rand(1000, 1000, device='cuda')
y = x * 2
print(torch.cuda.get_device_name(0), y.mean().item())
```

### TensorFlow-Test:
```python
import tensorflow as tf
tf.debugging.set_log_device_placement(True)
a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
b = tf.constant([[2.0, 0.0], [1.0, 3.0]])
c = tf.matmul(a, b)
print(c)
```

---

## Fehlerbehebung

Siehe Abschnitt **8** im ursprünglichen Entwurf für ausführliche Erklärungen zu häufigen Fehlern, z. B.:
- `nvidia-smi` gibt Fehler zurück
- `torch.cuda.is_available()` liefert `False`
- `libcudnn.so` wird nicht gefunden
- Versionskonflikte (CUDA, cuDNN)

---

## Best Practices

- GPU-Persistenzmodus aktivieren: `sudo nvidia-smi -pm 1`
- GPU-Auslastung überwachen: `watch -n1 nvidia-smi` oder `nvtop` installieren
- Mixed Precision Training verwenden für bessere Performance
- TensorBoard zur Trainingsvisualisierung nutzen

---

## Lizenz

```text
SPDX-License-Identifier: MIT

Beitragender: Jonas Zielke <contact@jonas-zeikle.de>
```

