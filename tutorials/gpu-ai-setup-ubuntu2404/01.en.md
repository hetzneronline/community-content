---
SPDX-License-Identifier: MIT
path: "/tutorials/gpu-ai-ubuntu-setup"
slug: "gpu-ai-ubuntu-setup"
date: "2025-03-31"
title: "Installing PyTorch, TensorFlow, and JupyterLab on Ubuntu 24.04 with GPU support"
short_description: "Learn how to install PyTorch, TensorFlow, and JupyterLab in a Conda environment with NVIDIA GPU support on Ubuntu 24.04."
tags: ["Ubuntu", "GPU", "PyTorch", "TensorFlow", "JupyterLab", "NVIDIA", "CUDA"]
author: "Jonas Zielke"
author_link: "Jonas-Zi3lke"
author_img: "https://github.com/account"
author_description: "jonas-zielke.de"
language: "en"
available_languages: ["en"]
header_img: "header-4"
cta: "dedicated-gpu"
---


## Introduction

This tutorial explains how to set up a powerful AI development environment on **Ubuntu 24.04**, optimized for training neural networks using a **NVIDIA GPU**. We'll use **Miniconda** to create a Python environment and install the latest versions of **PyTorch**, **TensorFlow**, and **JupyterLab** with full GPU support.

Along the way, we’ll install necessary NVIDIA drivers, CUDA Toolkit, and cuDNN. The guide also includes best practices, troubleshooting tips, and performance optimizations.

## Prerequisites

- A server running **Ubuntu 24.04**
- A **NVIDIA GPU**
- Administrator privileges (`sudo`)
- GPU-Server

---

## Step 1: System Preparation

Update and install essential packages:

```bash
sudo apt update && sudo apt upgrade -y
sudo apt install build-essential wget curl -y
```


---

## Step 2: Install the NVIDIA Driver

Ubuntu 24.04 includes `ubuntu-drivers` for detecting and installing GPU drivers.

1. **Detect available drivers:**
   ```bash
   ubuntu-drivers list --gpgpu
   ```

2. **Install recommended driver:**
   ```bash
   sudo ubuntu-drivers install --gpgpu
   ```

3. **Reboot your system:**
   ```bash
   sudo reboot
   ```

4. **Verify the installation:**
   ```bash
   nvidia-smi
   ```
   You should see your driver version listed.

---

## Step 3: Install CUDA Toolkit and cuDNN

### Install CUDA Toolkit:

```bash
sudo apt install -y nvidia-cuda-toolkit
```

Check the installation:
```bash
nvcc --version
```

### Install cuDNN:

1. Download cuDNN for CUDA 12.x from the [NVIDIA website](https://developer.nvidia.com/cudnn).
2. If you have a `.deb` package:

```bash
sudo dpkg -i cudnn-local-repo-ubuntu2404-*.deb
sudo apt update
sudo apt install libcudnn8 libcudnn8-dev
```

> ✅ Verify: `ls /usr/lib/x86_64-linux-gnu/libcudnn*` should list cuDNN libraries.

---

## Step 4: Install Miniconda

Download and install Miniconda:

```bash
curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
sh Miniconda3-latest-Linux-x86_64.sh
```

After installation:
```bash
source ~/.bashrc
```

Create and activate the Conda environment:
```bash
conda create -n ai_env python=3.10 -y
conda activate ai_env
```

---

## Step 5: Install PyTorch and TensorFlow with GPU Support

### Install PyTorch with CUDA:

```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
```

### Install TensorFlow with CUDA:

```bash
pip install --upgrade pip
pip install "tensorflow[and-cuda]"
```

> ✅ Verify GPU support:
```bash
python -c "import torch; print(torch.cuda.is_available())"
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

---

## Step 6: Install JupyterLab

Install JupyterLab:
```bash
conda install -c conda-forge jupyterlab -y
```

Optional: Register the environment as a Jupyter kernel:
```bash
conda install ipykernel -y
python -m ipykernel install --user --name ai_env --display-name "Python (ai_env)"
```

Start JupyterLab:
```bash
jupyter lab
```

---

## Step 7: Test GPU Acceleration

### PyTorch Test:
```python
import torch
x = torch.rand(1000, 1000, device='cuda')
y = x * 2
print(torch.cuda.get_device_name(0), y.mean().item())
```

### TensorFlow Test:
```python
import tensorflow as tf
tf.debugging.set_log_device_placement(True)
a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
b = tf.constant([[2.0, 0.0], [1.0, 3.0]])
c = tf.matmul(a, b)
print(c)
```

---

## Troubleshooting

See section **8** in the original draft for full error explanations, such as:
- `nvidia-smi` returns error
- `torch.cuda.is_available()` is False
- `libcudnn.so not found`
- Version mismatches (CUDA, cuDNN)

---

## Best Practices

- Enable GPU persistence mode: `sudo nvidia-smi -pm 1`
- Monitor GPU load: `watch -n1 nvidia-smi` or install `nvtop`
- Use mixed precision training for better performance
- Use TensorBoard for training visualizations

---

## License

```text
SPDX-License-Identifier: MIT

Contributor: Jonas Zielke contact@jonas-zeikle.de
```
