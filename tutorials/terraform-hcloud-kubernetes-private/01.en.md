---
SPDX-License-Identifier: MIT
path: "/tutorials/terraform-hcloud-kubernetes-private"
slug: "terraform-hcloud-kubernetes-private"
date: "2026-01-16"
title: "Private Kubernetes cluster via Terraform and Talos"
short_description: "This tutorial explains how to set up a private, production-ready Kubernetes cluster using Talos OS on Hetzner Cloud with proper NAT gateway configuration."
tags: ["Terraform", "Talos", "Kubernetes", "K8s"]
author: "Your Name"
author_link: "https://github.com/tmihalik"
author_img: "https://avatars.githubusercontent.com/u/440762"
author_description: ""
language: "en"
available_languages: ["en"]
header_img: "header-5"
cta: "cloud"
---

## Introduction

This tutorial guides you through setting up a private, production-ready Kubernetes cluster using Talos OS on Hetzner Cloud with proper NAT gateway configuration.

**Architecture Overview**

<div class="card" style="min-width: 40rem;max-width: 40rem;text-align: center;font-size:1rem;">
<!-- Beginning of Gateway -->
<div>
     <div class="card-header bg-light" style="font-size:1rem;display:inline-block;margin:1em;text-align:center;width:96%;">
         <div><b>Internet</b></div>
         </div>
</div>
<!-- End of Gateway -->
<!-- Beginning of Arrows -->
<div style="display: flex; justify-content: flex-start;text-align: center; gap: 10px; align-items: flex-start;">
     <!--- First arrow -->
     <div style="font-size:1rem; inline-block; width: 100%;">
           <kbd style="background-color:#EAE6F5;color:#000;">203.0.113.1</kbd>
          <div>↓</div>
          </div>
</div>
<!-- End of Arrows -->
<!-- Beginning of Gateway -->
<div class="card" style="margin:1rem;font-size:1rem;text-align:center;">
     <div>
     <div class="card-header " style="background: #e6f7ff; line-height:1.3rem;">
          Hetzner Load Balancer<br>
          <small>(Managed by Kubernetes) </small>
          </div>
     </div>
     <div class="card-body" style="background: #f0fbff;line-height:0.4rem;">
          <small>
          <div style="margin-bottom:1.5rem;margin-left:0.8rem;">Pvt IP: <kbd style="background-color:#E1F1D1;color:#000;">10.21.64.251</kbd>
          &emsp;&emsp;&emsp;&emsp;
          Pub IP: <kbd style="background-color:#EAE6F5;color:#000;">203.0.113.1</kbd></div>
          </small>
     <!--- Beginning of Row of cards -->
     <div style="display: flex; gap: 10px; margin-left: -0.9rem;margin-right: -0.9rem;">
     <!--- Beginning of left -->
     <div class="card" style="font-size:1rem; width: 49%; text-align:center;">
              <div class="card-header">
              <small>Port 80 &raquo; :30000</small>
          </div>
     </div>
     <!--- End of left-->
     <!---Beginning of right -->
     <div class="card" style="font-size:1rem; width: 49%; text-align:center;">
              <div class="card-header" >
              <small>Port 443 &raquo; :30001 </small>
          </div>
     </div>
     <!--- End of right -->
     </div>
     <!--- End of Row of cards -->
     </div>
</div>
<!-- End of Gateway -->
<!-- Beginning of Arrows -->
<div style="width: 100%rem;">
     <kbd style="background-color:#E1F1D1;color:#000;">10.21.0.0/16</kbd><br>
     <div>↓</div>
</div>
<!-- End of Arrows -->
<!-- Beginning of Gateway -->
<div>
     <div class="card-header" style="background: #F1FBEE;font-size:1rem;display:inline-block;margin:1em;text-align:center;width:96%;">
         <div>Private Network Gateway <kbd style="background-color:#E1F1D1;color:#000;">10.21.0.1</kbd></div>
         </div>
</div>
<!-- End of Gateway -->
<!-- Beginning of Arrows -->
<div style="display: flex; justify-content: flex-start;text-align: center; gap: 10px; align-items: flex-start;">
     <!--- First arrow -->
     <div style="font-size:1rem; inline-block; width: 13rem;">
          <kbd style="background-color:#E1F1D1;color:#000;">10.21.64.0/25</kbd><br>
          <div><br></div>
          <div>↓</div>
          </div>
     <!--- Second arrow -->
     <div style="font-size:1rem; inline-block; width: 13rem;">
          <kbd style="background-color:#E1F1D1;color:#000;">10.21.65.0/25</kbd><br>
          <div><br></div>
          <div>↓</div>
          </div>
     <!--- Third arrow -->
     <div style="font-size:1rem; inline-block; width:13rem;">
          <kbd style="background-color:#E1F1D1;color:#000;">10.21.0.0/24</kbd><br>
          <div><kbd style="background-color:#e2e2e2;color:#000;">0.0.0.0/0</kbd></div>
          <div>↓</div>
          </div>
</div>
<!-- End of Arrows -->
<!--- Beginning of Row of cards -->
<div style="display: flex; justify-content: flex-start; gap: 10px; margin: 1rem;align-items: flex-start;">
<!--- Beginning of first card -->
<div class="card" style="font-size:1rem; width: 25rem; text-align:center;font-size:1rem;">
     <div>
     <div style="line-height:2.2rem;">
          Kubernetes Cluster
          </div>
     </div>
     <!--- Beginning of Row of cards -->
     <div style="display: flex; gap: 6px; margin: 0.4rem;margin-top:0em;">
     <!--- Beginning of Control Plane Nodes -->
     <div class="card" style="font-size:1rem; width: 52%; text-align:center;font-size:1rem;">
          <div>
          <div class="card-header" style="background: #fff2f2;line-height:1.3rem;">
               <div style="margin-left:-1rem;margin-right:-1rem;margin-bottom:-1.3rem;">Control Plane Nodes</div><br>
               <small>(3 Talos VMs)</small>
               </div>
          </div>
          <div class="card-body" style="background: #fffafa;line-height:1.2rem;text-align:left;">
               <small>
               <div style="margin-bottom:0.8rem;margin-left:-0.5rem;">Pvt IP: <kbd style="background-color:#E1F1D1;color:#000;">10.21.64.X</kbd>
               <br>Pub IP: none</div>
               <ul style="margin-bottom:0.5rem;margin-left:-1.5rem;">
                   <li>etcd cluster</li>
                   <li>kube-apiserver</li>
                   <li>kube-scheduler</li>
               </ul></small>
          </div>
     </div>
     <!--- End of Control Plane Nodes-->
     <!---Beginning of Worker Nodes -->
     <div class="card" style="font-size:1rem; width: 52%; text-align:center;font-size:1rem;">
          <div>
          <div class="card-header" style="background: #fff2f2;line-height:1.3rem;">
               Worker Nodes<br>
               <small>(Talos VMs)</small>
               </div>
          </div>
          <div class="card-body" style="background: #fffafa;line-height:1.2rem;text-align:left;">
               <small>
               <div style="margin-bottom:0.8rem;margin-left:-0.5rem;">Pvt IP: <kbd style="background-color:#E1F1D1;color:#000;">10.21.64.X</kbd>
               <br>Pub IP: none</div>
               <ul style="margin-bottom:-0.5rem;margin-left:-1.5rem;">
                   <li>kubelet</li>
                   <li>kube-proxy</li>
                   <li>ingress-nginx</li>
                   <li>Longhorn storage</li>
                   <li>NodePorts 30000/1</li>
               </ul></small>
          </div>
     </div>
     <!--- End of Worker Nodes -->
     </div>
     <!--- End of Row of cards -->
</div>
<!--- End of first card -->
<!---Beginning of second card -->
<div class="card" style="margin-top:2.3rem;font-size:1rem; width: 13rem; text-align:center;font-size:1rem;">
     <div>
     <div class="card-header" style="background: #f3f6fa;line-height:1.3rem;">
          Egress VM<br>
          <small>(Management Node) </small>
          </div>
     </div>
     <div class="card-body" style="background: #fafbfe;line-height:1.2rem;text-align:left;">
          <small>
          <div style="margin-bottom:0.8rem;margin-left:-0.5rem;">Pvt IP: <kbd style="background-color:#E1F1D1;color:#000;">10.21.0.2</kbd>
          <br>Pub IP: <kbd style="background-color:#EAE6F5;color:#000;">192.0.2.254</kbd></div>
          <ul style="margin-bottom:-0.5rem;margin-left:-1.5rem;">
          <li>Public IP (SSH access) </li>
          <li>Private IP (NAT gateway) </li>
          <li>kubectl/talosctl tools</li>
          <li>Routes traffic to internet</li>
          </ul></small>
          </div>
</div>
<!--- End of second card -->
</div>
<!--- End of Row of cards -->
</div>

<br>

**Traffic Flow:**
- **Inbound**: Internet → Load Balancer → Private Network Gateway → Kubernetes Worker NodePorts → ingress-nginx → Services
- **Outbound**: Kubernetes Nodes → Private Network Gateway → Egress VM (NAT) → Internet  
- **Management**: SSH to Egress VM → kubectl/talosctl to Kubernetes cluster

**Prerequisites**

- [Hetzner Console](https://console.hetzner.com/) account and [API token](https://docs.hetzner.com/cloud/api/getting-started/generating-api-token)
- Basic knowledge of Kubernetes and networking
- Understanding of Talos OS concepts

## Step 1 - Set Up NAT Gateway and Private Network

This step explains how to set up the egress VM from the visualization above as NAT gateway.

Before creating the Kubernetes cluster, you need to set up a private Network with NAT gateway for internet access. Follow the official Hetzner tutorial:

**[How to set up NAT for Cloud Networks](https://community.hetzner.com/tutorials/how-to-set-up-nat-for-cloud-networks)**

Do the following:

> You do NOT need the client servers. You should only follow the steps for creating and setting up the **Private Network** and the **NAT server**. Use `10.21.0.0/16` for the Network.

| Steps to follow | Description |
| ---------- | ----------- |
| [Step 1](https://community.hetzner.com/tutorials/how-to-set-up-nat-for-cloud-networks#step-1---creating-the-network-and-servers) | Create a new Network as explained in that step. You can set it to `10.21.0.0/16` |
| [Step 6](https://community.hetzner.com/tutorials/how-to-set-up-nat-for-cloud-networks#step-6---cloud-init) | [Create a new server](https://docs.hetzner.com/cloud/servers/getting-started/creating-a-server).<ul><li>Networking<br>Select the Network you just created.</li><li>Cloud config<br>Copy&paste the NAT server script provided in that step. Remember to change 10.0.0.0/16 to 10.21.0.0/16.</li></ul>If you already have an existing server that should serve as the NAT gateway, you can instead follow the instructions for the NAT server in Step 3 and Step 4 to set everything up manually.  |
| [Step 2](https://community.hetzner.com/tutorials/how-to-set-up-nat-for-cloud-networks#step-2---adding-the-route-to-the-network) | Add the route to the Network as explained in that step. Set the server you just created (or the existing server you just configured) as the Gateway. |
| [Conclusion](https://community.hetzner.com/tutorials/how-to-set-up-nat-for-cloud-networks#conclusion) | Configure the firewall |

In the steps below, you will need the Network ID for `hcloud_network_id`. When you select your Network in Hetzner Console, the URL in the address bar of the browser contains the Network ID:

```
https://console.hetzner.com/projects/<project-id>/networks/<network-id>/resources
```

## Step 2 - Install prerequisites

In Step 1, you created and configured an egress VM to act as a NAT gateway for the Kubernetes nodes.

On that egress VM, install the following as explained in their official documentation:

- [Terraform](https://developer.hashicorp.com/terraform/install) (>= 1.0)
- [Packer](https://developer.hashicorp.com/packer/install)
- [jp](https://jqlang.org/download/)
- [talosctl](https://www.talos.dev/latest/talos-guides/install/talosctl)
- [kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/)

`kubectl` / `talosctl` are needed to access the Kubernetes cluster from the egress VM.

## Step 3 - Create Project Directory

Now that the egress VM works as a NAT gateway and has all the prerequisites installed, you can create a new directory for the project files:

```bash
mkdir k8s-cluster && cd k8s-cluster
```

## Step 4 - Configure Terraform Variables

In the new directory `k8s-cluster` on the egress VM, add the following files:

* Create `variables.tf`:
  ```hcl
  variable "hcloud_token" {
    description = "Hetzner Cloud API token. Prefer to supply via TF_VAR_hcloud_token or terraform.tfvars, or rely on provider using HCLOUD_TOKEN env."
    type        = string
    sensitive   = true
  }
  ```
  
  <details>
  <summary>Optional: S3 Backup Variables (Click to expand)</summary>
  
  <blockquote>
  
  If you want to enable S3 backup for Talos configuration, add these additional variables to your `variables.tf`:
  
  ```hcl
  variable "talos_backup_s3_access_key" {
    description = "S3 Access Key for Talos Backup."
    type        = string
    sensitive   = true
    default     = ""
  }
  
  variable "talos_backup_s3_secret_key" {
    description = "S3 Secret Access Key for Talos Backup."
    type        = string
    sensitive   = true
    default     = ""
  }
  
  variable "talos_backup_s3_bucket" {
    description = "S3 bucket name for Talos backups."
    type        = string
    default     = ""
  }
  
  variable "talos_backup_s3_endpoint" {
    description = "S3 endpoint hostname for Talos backups."
    type        = string
    default     = ""
  }
  
  variable "talos_backup_s3_region" {
    description = "S3 region for Talos backups."
    type        = string
    default     = ""
  }
  ```

  </blockquote>  
  </details>

<br><br>

* Create `terraform.tfvars` or set your token via environment variable
  ```bash
  # Option 1: Environment variable
  export TF_VAR_hcloud_token="your-hetzner-cloud-api-token"
  
  # Option 2: Create terraform.tfvars file
  echo 'hcloud_token = "your-hetzner-cloud-api-token"' > terraform.tfvars
  ```

  <details>
  <summary>Optional: S3 Backup Variables (Click to expand)</summary>
  
  <blockquote>
  
  If you want to enable S3 backup for Talos configuration, add these additional variables to your `terraform.tfvars`:
  
  ```bash
  echo 'talos_backup_s3_access_key = "your-access-key"' > terraform.tfvars
  echo 'talos_backup_s3_secret_key = "your-secret-key"' > terraform.tfvars
  echo 'talos_backup_s3_bucket = "your-bucket-name"' > terraform.tfvars
  echo 'talos_backup_s3_endpoint = "your-endpoint"' > terraform.tfvars
  echo 'talos_backup_s3_region = "your-region"' > terraform.tfvars
  ```

  </blockquote>  
  </details>

<br><br>

* Create `kubernetes.tf` with the main cluster configuration
  
  > See [registry.terraform.io](https://registry.terraform.io/modules/hcloud-k8s/kubernetes/hcloud/latest)

  Replace `YOUR_NETWORK_ID_HERE` with your actual Network ID.
  
  ```hcl
  module "kubernetes" {
    source  = "hcloud-k8s/kubernetes/hcloud"
    version = "3.20.1"
  
    cluster_name = "k8s"
    hcloud_token = var.hcloud_token
  
    # Export configs for Talos and Kube API access
    cluster_kubeconfig_path  = "kubeconfig"
    cluster_talosconfig_path = "talosconfig"
  
    # Optional Ingress Controller, Cert Manager and Storage
    cert_manager_enabled  = true
    ingress_nginx_enabled = true
    longhorn_enabled      = true
  
    network_ipv4_cidr = "10.21.0.0/16"
  
    # Private nodes, egress via your own gateway VM
    talos_public_ipv4_enabled = false
    talos_public_ipv6_enabled = false
  
    control_plane_nodepools = [
      { name = "control", type = "cx23", location = "hel1", count = 3 }
    ]
    
    worker_nodepools = [
      # placement_group = true ensures VMs are distributed across different physical servers
      { name = "worker-hel-ccx", type = "ccx23", location = "hel1", count = 3, placement_group = true },
    ]
  
    cluster_healthcheck_enabled = true
    firewall_use_current_ipv4 = false
    firewall_use_current_ipv6 = false
    cluster_access = "private"
    talos_extra_routes = ["0.0.0.0/0"]
    network_native_routing_ipv4_cidr = "10.0.0.0/8"
  
    # Use your existing Network ID from the NAT gateway setup (Step 1)
    # You can find this in Hetzner Cloud Console -> Networks or via: hcloud network list
    hcloud_network_id = YOUR_NETWORK_ID_HERE
  
    control_plane_private_vip_ipv4_enabled = true
    ingress_nginx_kind = "DaemonSet"
    ingress_nginx_service_external_traffic_policy = "Local"
  
    ingress_load_balancer_pools = [
      {
         name          = "regional-lb-hel"
        location      = "hel1"
      }
    ]
  
    cluster_autoscaler_nodepools = [
      {
        name     = "autoscaler"
        type     = "ccx23"
        location = "hel1"
        min      = 0
        max      = 6
        labels   = { "autoscaler-node" = "true" }
        taints   = [ "autoscaler-node=true:NoExecute" ]
      }
    ]
  
    cluster_delete_protection = true
  }
  ```
  
  <details>
  <summary>Optional: S3 Backup Configuration (Click to expand)</summary>
  <blockquote>
  
  If you added the S3 backup variables to your `variables.tf`, include these lines in your `kubernetes.tf` module configuration:
  
  ```hcl
  # Add these lines inside the module "kubernetes" block above
    talos_backup_s3_endpoint   = var.talos_backup_s3_endpoint
    talos_backup_s3_region     = var.talos_backup_s3_region
    talos_backup_s3_bucket     = var.talos_backup_s3_bucket
    talos_backup_s3_access_key = var.talos_backup_s3_access_key
    talos_backup_s3_secret_key = var.talos_backup_s3_secret_key
  ```
  
  </blockquote>
  <br>
  </details>

You'll need these files in your working directory:

| File                 | Description |
| -------------------- | ----------- |
| **variables.tf**     | Variable definitions (with optional S3 variables) |
| **kubernetes.tf**    | Main cluster configuration (with optional S3 configuration) |
| **terraform.tfvars** | Your actual values (or use environment variables) |

## Step 5 - Deploy the Cluster

Note that `terraform apply` will create chargeable resources in Hetzner Console. Terraform will create several chargeable cloud servers, a chargeable Load Balancer, chargeable Snapshots, a Firewall, Placement Groups, and more.

The number of control plane nodes and worker nodes is defined via `count = #` in `kubernetes.tf`.

Initialize and apply the Terraform configuration:

```bash
terraform init -upgrade
terraform apply
```

Review the planned changes and confirm the deployment. This process will:

1. Create Talos images using Packer
2. Deploy control plane and worker nodes
3. Configure the Kubernetes cluster
4. Set up ingress controllers and cert-manager
5. Configure Longhorn for persistent storage

## Step 6 - Access Your Cluster

After successful deployment, you'll find the configuration files in your current directory:

```bash
export TALOSCONFIG=talosconfig
export KUBECONFIG=kubeconfig
```

Verify your cluster is running:

```bash
# Check Talos cluster members
talosctl get member

# Check Kubernetes nodes
kubectl get nodes -o wide

# Check all pods across namespaces
kubectl get pods -A
```

## Step 7 - Configuration summary and enhancement suggestions

**Configuration Highlights**

* Private Network Setup
  - **Network CIDR**: `10.21.0.0/16`
  - **No public IPs**: All Kubernetes nodes are private
  - **Egress routing**: Traffic flows through your gateway VM

* High Availability Features
  - **Control plane**: 3 nodes for HA
  - **Worker nodes**: Distributed across Placement Groups (ensures VMs run on different physical hardware for better reliability)
  - **Ingress**: Load Balancer with DaemonSet configuration
  - **Storage**: Longhorn for distributed persistent storage

* Security Features
  - **Private cluster access**: No direct internet access to nodes
  - **Firewall**: Controlled access through security groups
  - **Backup**: Optional S3 backup for Talos configuration

<br>

-----

**Scaling to Full High Availability**

For a production-ready, fully high-available setup, consider these enhancements:

* Multiple Egress VMs
  
  Deploy additional egress VMs in different locations with failover configuration:
  - Set up multiple gateway VMs across different zones
  - Configure VRRP (Virtual Router Redundancy Protocol) for automatic failover
  - Use BGP routing for advanced traffic management

<br>

* Multi-Region Load Balancers
  ```hcl
  ingress_load_balancer_pools = [
    {
      name          = "regional-lb-fsn"
      location      = "fsn1"
      local_traffic = true
    },
    {
      name          = "regional-lb-nbg"
      location      = "nbg1"
      local_traffic = true
    },
    {
      name          = "regional-lb-hel"
      location      = "hel1"
      local_traffic = true
    }
  ]
  ```

<br>

* Cross-Zone Worker Distribution
  ```hcl
  worker_nodepools = [
    # Each placement_group = true ensures nodes within each location are on different physical servers
    { name = "worker-fsn", type = "cpx42", location = "fsn1", count = 2, placement_group = true },
    { name = "worker-nbg", type = "cpx42", location = "nbg1", count = 2, placement_group = true },
    { name = "worker-hel", type = "cpx42", location = "hel1", count = 2, placement_group = true },
  ]
  ```

<br>

* Additional HA Components
  - **External DNS**: Automatic DNS management for services
  - **Monitoring**: Prometheus and Grafana for observability
  - **Backup strategies**: Regular etcd and persistent volume backups
  - **Disaster recovery**: Cross-region backup and restore procedures
  
  This setup provides a robust, private Kubernetes cluster that can handle production workloads while maintaining security and high availability standards.

<br>

-----

**Troubleshooting**

* Common Issues
  1. **Network connectivity**: Ensure your egress VM's NAT rules are correctly configured
  2. **DNS resolution**: Verify that private nodes can resolve external DNS through the gateway
  3. **Load Balancer access**: Check that ingress controllers are properly configured for private network access

* Useful Commands
  ```bash
  # Check Talos node status
  talosctl -n <node-ip> get nodeready
  
  # Check network connectivity from nodes
  talosctl -n <node-ip> get links
  
  # Restart Talos services if needed
  talosctl -n <node-ip> restart systemd-networkd
  ```

## Conclusion

With this configuration, you have a fully private, production-ready Kubernetes cluster running on Hetzner Cloud that can scale to meet your needs while maintaining high security and availability standards.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: [submitter's name and email address here]

-->
