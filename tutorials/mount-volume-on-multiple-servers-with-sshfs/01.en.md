---
SPDX-License-Identifier: MIT
path: "/tutorials/mount-volume-on-multiple-servers-with-sshfs"
slug: "mount-volume-on-multiple-servers-with-sshfs"
date: "2020-07-17"
title: "Mount Hetzner Cloud volume on multiple Debian servers with `sshfs`, including Ansible role"
short_description: ""
tags: ["Hetzner Cloud", "Volume", "sshfs", "Ansible"]
author: "Timo L.R. Halbesma"
author_link: "https://github.com/tlrh314"
author_img: "https://avatars2.githubusercontent.com/u/3819793?s=460&u=02b56963dbb97eebea691eb172a04efc9316f4f7&v=4"
author_description: "Hobbyist GNU/Linux power user"
language: "en"
available_languages: ["en"]
header_img: "header-x"
---

## Introduction

I have frequently seen mentions of the Hetzner Cloud Volume "limitation" that they can only be mounted on one server. Over the last year I ran a production cluster with a Hetzner Cloud Volume mounted on multiple Hetzner Cloud Servers via `sshfs`. This tutorial describes how to set this up on two fresh `debian-10` `cx11` instances using the `hcloud` [Command-line interface for Hetzner Cloud](https://github.com/hetznercloud/cli), and how to configure `sshfs` manually or with an optional [Ansible](https://docs.ansible.com/ansible/latest/index.html) role.

**Prerequisites**

We assume that `hcloud` and `ansible` are installed. If this isn't the case: on macOS this could, for example, be done using [Homebrew](https://brew.sh/). We refer to the [hcloud/cli README](https://github.com/hetznercloud/cli#third-party-packages) and [Ansible documentation](https://docs.ansible.com/ansible/latest/installation_guide/intro_installation.html) for installation instructions on other operating systems.

```bash
brew install hcloud
brew install ansible
```

At times of writing this installs the following software versions.

- `hcloud` version 1.17.0
- `ansible` 2.9.10
- hcloud-python 1.8.1


## Step 1 - Create a project, add an API token, and setup `hcloud`

If you haven't already, first create a project `<myproject>` in your [Hetzner Cloud Console](https://console.hetzner.cloud/) and generate an API token via Security > API Tokens > Generate API Token. Next, open up a terminal and execute the following.

```bash
source <(hcloud completion bash)   # if you want command completion - trust me, you do!
hcloud context create myproject
hcloud context list
hcloud context activate myproject  # only if it isn't active just yet
```

Note that `hcloud context create` stores the API token in `~/.config/hcloud/cli.toml`. This confused me at first because the [hcloud/cli README](https://github.com/hetznercloud/cli#configure-hcloud-using-environment-variables) suggests that the context and token are taken from the environment variable `HCLOUD_CONTEXT` and `HCLOUD_TOKEN`, respectively. However, the shell variables seem to be ignored in favour of  `~/.config/hcloud/cli.toml`.

## Step 2 - Create 2 servers and 1 cloud volume

With the project and API token in place it is time to fire up 2 servers and 1 volume. Note that the volume named `<storage>` will belong to one of your servers (`<server1>`) while the other server(s) mount it later on via `sshfs`. For convenience we first add our SSH [public key](https://en.wikipedia.org/wiki/Public-key_cryptography) to our Hetzner Cloud project such that we can add the key to the server on creation.

```bash
# If you don't have an ssh key, first create it
ssh-keygen -t rsa -C "MyComputer --> Hetzner Cloud"

# Add the ssh key to the Hetzner Cloud project
hcloud ssh-key create --public-key-from-file=~/.ssh/id_rsa.pub --name my-ssh-key

# Create 2 cx11 servers with debian-10 in Neuremberg that are accessible wih your ssh key
hcloud server create --ssh-key my-ssh-key --location nbg1 --type cx11 --image debian-10 --name server1
hcloud server create --ssh-key my-ssh-key --location nbg1 --type cx11 --image debian-10 --name server2

# Create 1 volume of 10GB that is ext4 formatted, belongs to server1, and added to /etc/fstab to automount
hcloud volume create --size 10 --name storage --server server1 --format ext4 --automount
```

## Step 3 - Configure `sshfs` to mount the volume on `<server2>`

We are now going to configure `sshfs` to mount the volume from `<server1>` to `<server2>`. Don't worry if you're not familiar with [Ansible](https://docs.ansible.com/ansible/latest/index.html)! All the following steps in this tutorial can be executed manually, but Ansible just automates it (very useful in case you'd like to add more servers but dislike repetitive tasks). 

TODO

## Limitations
- This tutorial limits the scope to 2 servers only, but you can easily extend this to N servers.
- The order of (re)booting the servers is important! If `<server1>` is not reachable from `<server2>` on boot, then the volume will of course not be mounted! The described solution is thus not entirely fool-proof and caution is required when (re)booting your servers. In some cases a manual mount may be needed.
- I have been unable to find (many) sources online that describe in-depth the resource usage, stability, security, and resilience of this setup. My use-case is to make static assets (100 GB of images/css/js) available on 3 application (backend) servers in Hetzner Cloud, and on an nginx reverse proxy that lives on 1 dedicated root server at Hetzner Online. There is some CPU overhead for `sshfs`, but overall it does not seem to affect performance too drastically and the volume seems to have been available smoothly without interruption (except when it wasn't mounted after reboot, see previous point). 

## Conclusion

Congratulations, you now have a Hetzner Cloud Volume that is available on all of your Hetzner Cloud Servers, overcoming the "limitation" that a Volume is only available on one Server. Moreover, you can also mount the Cloud Volume on your dedicated root server. It's time for a celebratory beer.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: Timo Halbesma <timo@halbesma.com>

-->
