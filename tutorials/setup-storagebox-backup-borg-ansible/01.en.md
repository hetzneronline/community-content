---
SPDX-License-Identifier: MIT
path: "/tutorials/setup-storagebox-backup-borg-ansible"
slug: "setup-storagebox-backup-bord-ansible"
date: "2021-04-28"
title: "Setup Borg-Backup to Hetzner Storagebox with ansible :+1:"
short_description: "Autmatically setup borg backup to the Hetzner Storage Box"
tags: ["StorageBox", "backup", "borg", "ansible"]
author: "Dirk Jugov"
author_link: "https://github.com/zapalotta"
author_img: "https://avatars.githubusercontent.com/u/6747521"
author_description: ""
language: "en"
available_languages: ["en"]
header_img: "header-2"
---

## Introduction

I am running multiple VMs on multiple Servers. Most of them on Hetzner Rootservers, some on my personal server at home. I used to use rsync based backups to the former Hetzner Backupspace and then the current storagebox using [Autofs](https://community.hetzner.com/tutorials/setup-autofs-mount-storagebox), but never really liked that solution.   

I stumbled upon [Borg Backup](https://www.borgbackup.org) a while ago but never really liked the command line. I also tried borgmatic, but I am personally not to fond of having to have an extra virtual env for that. As I am using [Ansible](https://docs.ansible.com) for almost anything anyways, why not use that.

**Prerequisites**

Besides having a Linux or FreeBSD server and a [Hetzner Storage Box](https://www.hetzner.com/storage/storage-box), you will need to set up [SSH keys for the storage box](https://docs.hetzner.com/de/robot/storage-box/backup-space-ssh-keys/). If you backup multiple machines, you better use one host (a server or your Linux or MacOS based Computer) for running ansible on it. You should be able to log in using a ssh certificate with a user with sudo rights or as root from the ansible host to the servers to be backupped.  

This tutorial is based on Debian/Ubuntu. It should also work on SUSE or RedHat based distros, though the package names could differ.

For test and check purposes, it is very helpful mounting the storagebox on one host, e.g. using the above mentioned automounter.


## Ansible Setup ##

You can skip this chapter to Step 1 if you are already familiar with ansible. 

If you have never used ansible, you may start with some smaller howtos, like using ansible to install a webserver or create a user. I will cover the basic steps anyway.

You need to do the following steps on the management host, it will use ansible to connect to the managed host (the server which you want to have borg installed on)

### Ansible basics 

* What is ansible

Ansible is a tool which uses declarative structured (i.e. yu define, how you the managed system to be) configs and applies them to one or many managed servers. It only needs python installed on the managed system (almost always available on Linux and other unix like systems). Ansible consist 

* Modules

Ansible consists mainly of many modules, each of which can fulfill specific tasks, like installing packages, managing firewall etc. These modules are usually python scripts or similar, many are delivered together with ansible, many more can be downloaded from e.g. [Ansible Galaxy](https://galaxy.ansible.com) or e.g. GitHub. Modules can also be written by yourself.

* Facts
Ansible can gather facts from the managed system, e.g. the used OS and version, diskspace, network settings etc. These facts can later be used for the configuration.
Facts can also be defined using variables for hosts etc.

* Tasks

A task in ansible is one step, calling a module for one single tasks, e.g. install a specific package.
Example:
```yaml
- name: Install the htop package
  package: 
    name: htop
    state: present
```
In this example, the ansible module "package" is used to install the package "htop".

* Roles

A Role is a set of files consisting of some tasks and files or templates which are applyed to the managed system

* Playbook

A playbook is a list of tasks and/or roles which are applyed to the managed hosts.


* Inventories

Ansible works on an inventory. The simplest inventory is a single host, but usually there is an inventory file with a list of hosts, often grouped and also with host spacific variables. 


* Modes

There are basically two modes: 

Ad hoc mode: Call ansible with the ansible command using one module on a defined inventory interactively on the shell. We use this mode later for basic tests.

Play mode: Call ansible with the ansible-playbook command applying many tasks/roles on the invetory.


### Install ansible

Use your package manager to install ansible, e.g. ```apt-get install ansible```

### Test if ansible can connect to the server to be managed

We use the ping module. This must not be confused with the ICMP ping command. The ansible ping module logs into the managed system using ansible and therefore checks if everything is set up correctly.

```bash
sysadmin@manager:~/ansible 2 $ ansible -i managed, -m ping all
[WARNING]: Platform linux on host docker is using the discovered Python interpreter at /usr/bin/python, but future installation of another Python interpreter
could change this. See https://docs.ansible.com/ansible/2.9/reference_appendices/interpreter_discovery.html for more information.
docker | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    },
    "changed": false,
    "ping": "pong"
}
```
## What will happen

The Ansible roll will do the following:

* create a sub-storagebox on the storagebox
* create a ssh key pair for the sub-storagebox and install the private key on the managed server
* Install borg backup on the managed server
* Install some bash scripts for borg on the managed host
* place a config file /etc/borg_backup.conf on the managed host with credentials for the sub storagebox and borg settings. This file is used by the bogr shellscripts
* Initialize a borg repo on the storagebox
* Install a cronjob for borg
* Write the borg key and ssh keypair in a folder on the manage host (keep these files in a safe place!)


## Step 1 - get the role 

Do this on the management host: 

```bash
$ git clone https://github.com/zapalotta/hetznerbackup.git
```

## Step 2 - Prepare the inventory

Create a file called hosts.yml with the following content. This is YAML, so: indendation matters, and never use tabs!


```yaml
backuphosts:
  hosts:
    targethost
  vars:
    hetzner_webservice_user: "XXXXXXX"                               
    hetzner_webservice_pass: "XXXXXXX"
    hetzner_server_id: "123456"                                       
#    hetzner_storagebox_id: "98765"                                   
    hetznerbackup_master_user: uXXXXXXX                               
    hetznerbackup_master_storagebox: uXXXXXXX.your-backup.de          
    hetznerbackup_default_rsakey: ~/.ssh/id_rsa_hetznerbackup         
    hetznerbackup_additional_include_dirs:                            
      - "/tmp"
    hetznerbackup_additional_exclude_dirs:                            
      - "/foo"
    hetznerbackup_cron_hour: 1                                        
    hetznerbackup_cron_minute: 0                                      

    hetznerbackup_keydir: /tmp/hetznerbackup_keys                     

```

<dl>
  <dt>targethost</dl>
  <dd>Managed host, where borg is to be installed</dd>
  <dt>hetzner_webservice_user</dt>
  <dd>Webservice user for hetzner services. Get from hetzner robot -> Settings -> Webservice user</dd>
  <dt><hetzner_webservice_pass</dt>
  <dd>Password for webservice user</dd>
  <dt>hetzner_server_id</dt>
  <dd>Get from Hetzner Robot -> Server. e.g. EX41S #123456</dd>
  <dt>hetzner_storagebox_id</dt>
  <dd>OPTIONAL: If you already have a dedicated sub storagebox for this backup, put it's ID here. Otherwise, one is created.</dd>
  <dt>hetznerbackup_master_user</dt>
  <dd>User for the main storagebox</dd>
  <dt>hetznerbackup_master_storagebox</dt>
  <dd>ID of the main storagebox</dd>
  <dt>hetznerbackup_default_rsakey</dt>
  <dd>rsa key for the main storage box</dd>
  <dt>hetznerbackup_additional_include_dirs</dt>
  <dd>OPTIONAL: List of folders to be additionally backuped. Defaults see github.</dd>
  <dt>hetznerbackup_additional_exclude_dirs</dt>
  <dd>OPTIONAL: List of folders to be excluded from backup. Defaults see github.</dd>
  <dt>hetznerbackup_cron_hour</dt>
  <dd>Hour on which the backup cronjob will be running</dd>
  <dt>hetznerbackup_cron_minute</dt>
  <dd>Minute of the hour when the cronjob will be running</dd>
  <dt>hetznerbackup_keydir</dt>
  <dd>Folder on the managER node (yor ansible host) where secrets for the backup will be written to</dd>
</dt>

This example will set up all hosts mentioned in hosts: with the same settings (includes, excludes, cronjob). You can use [host variables](https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#assigning-a-variable-to-one-machine-host-variables) to configure multiple hosts with different settings



## Step 3 - Run Ansible 


```
master_map_name = etc/auto.master
```

The main config file which defines all maps (a map is basically one automount directory).

```
timeout = 300
```

Number of seconds of inactivity on the folder before it gets unmounted.

```
browse_mode = no
```

Disabling browse_mode hides the mount folders. E.g. if you do a `ls /srv` you won't see the folder `storagebox/`. After doing `ls /srv/storagebox`, it appears. Enabling browse mode will have an impact on performance of `ls`.

Please note that on RedHat based distros some of these settings are abstracted and defined in `/etc/sysconfig/autofs`!

### Step 3.2 - auto.master file

Even though you can place mappings in `/etc/auto.master.d` I personally prefer adding the entries directly to this file.

So simply add the following line *before* the last line `+auto.master`

```
/srv	/etc/auto.storagebox
```

This means that the map in `/etc/auto.storagebox` will be mounted in `/srv`.

### Step 3.3 - auto.storagebox file

The file `/etc/auto.storagebox` contains the folder to be mounted (relative to the base folder) and the mount options.

```
storagebox -fstype=fuse,rw,nodev,nonempty,noatime,allow_other,max_read=65536,IdentityFile=/root/.ssh/id_rsa_storagebox :sshfs\#iholu@holu.your-backup.de\:
```

The complete line explained:

* storagebox
  * The name of the folder where the storage box is mounted (/srv/storagebox)
* -fstype=fuse
  * User fuse as fstype, following are the mount options
* rw
  * ReadWrite access as opposed to ro, ReadOnly
* nodev
  * No special devices (e.g. /proc) can be seen on this mount. For security reasons, though probably not neccessary on the storagebox.
* nonempty
  * Mount can even work if the target folder is not empty
* noatime
  * sshfs does not handle atime (time of last access of a file) properly
* allow_other
  * All users, not just root, can use the mounted folder
* max_read=65536
  * Maximum size of a read request.
* IdentityFile=/root/.ssh/id_rsa_storagebox
  * The ssh file used to access the storage box (See prerequisites)

## Step 4 - Start autofs

```
$ systemctl start autofs
```

## Step 5 - Test autofs

Simply `ls` the folder or `cd` to it

```
$ ls /srv/storagebox
```

```
$ cd /srv/storagebox
```

You should now see the contents of the storage box.

## Conclusion

By following this tutorial you have now set up automatic mounting of a Hetzner Storage Box.

##### License: MIT

<!--

Contributor's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: Dirk Jugov <dirk@jugov.de> 

-->
