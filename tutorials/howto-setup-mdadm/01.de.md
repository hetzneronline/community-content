---
SPDX-License-Identifier: MIT
path: "/tutorials/howto-setup-mdadm/de"
slug: "howto-setup-mdadm"
date: "2019-06-18"
title: "Software RAID unter Linux"
short_description: "Installation und Konfiguration eines Software RAIDs (mdadm) auf Linux-Systemen."
tags: ["Linux", "RAID", "mdadm"]
author: "Markus"
author_link: "https://github.com/BackInBash"
author_img: "https://avatars3.githubusercontent.com/u/48181660"
author_description: ""
language: "de"
available_languages: ["de", "en"]
header_img: "header-8"
cta: "dedicated"
---

## Einleitung

In diesem Tutorial wird erklärt wie man `mdadm` Software RAIDs auf Linux-Systemen installiert, einrichtet und verwaltet. In den einzelnen Schritten wird als Beispiel ein Server mit zwei Blockspeicher-Datenträgern verwendet. Es wird kurz erklärt, wie man die Datenträger formatiert und auf diesen jeweils eine Partition erstellt. Anschließend wird mit diesen beiden Partitionen ein RAID-Verbund erstellt.

**Voraussetzungen**

* 1 Server
  * Installiertes Linux OS
  * Root-Zugriff oder Benutzer mit sudo-Rechten
  * Mind. zwei freie Partitionen auf zwei verschiedenen Festplatten

**Beispiel-Benennungen**

* **RAID**
  * <kbd>md0</kbd>
  * Gerätedatei: `/dev/md0`
  * Einhängepunkt: `/mnt/<your-mount-point>`

* **Festplatten und Partitionen**
  * <kbd>sda</kbd> `sda1` `sda2` `sda3`
  * <kbd>sdb</kbd> `sdb1`
  * <kbd>sdc</kbd> `sdc1`

In den folgenden Beispiel-Befehlen wird RAID <kbd>md0</kbd> mit den Partitionen `sdb1` und `sdc1` erstellt.

## Schritt 1 - Vorbereitungen

Als erstes sollte man sich Gedanken darüber machen, welches RAID-System man betreiben möchte. Dies ist zum einen davon abhängig, welches Ziel man verfolgt und zum anderen wie viele Festplatten im Server selbst verbaut sind.

> ***Hinweis:*** *Ein RAID sollte nicht als Datensicherung gesehen werden, da es keinen Schutz vor Datenverlust bietet, sondern nur die Verfügbarkeit der Daten erhöht.*

### Schritt 1.1 - Auswahl des RAID-Levels

Die Auswahl des richtigen RAID-Levels ist nicht ganz einfach und hängt von mehreren Faktoren ab:

* Wie viele Festplatten bietet der Server?
* Welche Ziele verfolgt man?
  * Mehr Speicherplatz / Geringere Verfügbarkeit
  * Höhere Verfügbarkeit / Weniger Speicherplatz

------------

<u>Eine Liste der meistverwendeten RAID-Level:</u>

| RAID-Level | Beschreibung |
| ---------- | ------------ |
| RAID0      | Ist ein Verbund aus **zwei oder mehr Partitionen**. Dabei werden die Partitionen logisch zu einer Partition vereint. Hier findet eine Erniedrigung der Verfügbarkeit statt. Ist eine der Festplatten defekt sind ***automatisch alle Daten verloren***.<br>[Weitere Informationen zu RAID0](https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_0) |
| RAID1      | Ist ein Verbund aus **zwei oder mehr Partitionen**. Dabei befinden sich die Daten jeweils gespiegelt auf den beiden Partitionen.<br>[Weitere Informationen zu RAID1](https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_1) |
| RAID5      | Ist ein Verbund aus **drei oder mehr Partitionen**. Dabei befinden sich die Daten jeweils gespiegelt auf zwei der drei Partitionen. Auf der dritten Partition, werden so genannte "Paritäten" gespeichert, mit dessen Hilfe es möglich ist, Daten auf defekten Festplatten im RAID wiederherzustellen.<br>[Weitere Informationen zu RAID5](https://en.wikipedia.org/wiki/Standard_RAID_levels#RAID_5) |

Vor- und Nachteile:

| RAID0 | RAID1 | RAID5 |
| ----- | ----- | ----- |
| <ul><li>Erhöht den Verfügbaren Speicherplatz</li><li>Erhöht die Festplatten Performance</li></ul> | <ul><li>Erhöht die Ausfallsicherheit / Verfügbarkeit der Daten</li><li>Erhöht die Lesegeschwindigkeit der Daten</li></ul> | <ul><li>Erhöhte Ausfallsicherheit / Verfügbarkeit der Daten.</li><li>Optimale Speichernutzung</li><li>Erhöht die Lesegeschwindigkeit der Daten</li></ul>  |
| <ul><li>Bei einem Festplatten Ausfall sind die Daten aller Festplatten verloren</li></ul> | <ul><li>Der verfügbare Speicherplatz halbiert sich</li></ul> | <ul><li>Weniger Performance bei Schreibzugriffen</li></ul> |

<u>Eine Liste weiterer RAID-Levels, die weniger häufig verwendet werden:</u>

* **Linear:** Aneinanderhängen von mehreren Partitionen
* **Multipath:** Kein RAID, sondern ein Mapping einer Datei auf zwei verschiedene Pfade auf der gleichen Partition (Spiegelung)
* **Faulty:** Emuliert ein fehlerhaftes RAID-System für Testfälle
* **Level 4:** Wie Level 0, aber mit einem zusätzlichen Device für Paritätsbits (erhöhte Ausfallsicherheit).
* **Level 6:** Wie Level 5 aber mit zwei unabhängigen Paritätsbits pro Segment (erhöhte Ausfallsicherheit).

### Schritt 1.2 - Auflistung der Festplatten im System

Für eine kurze und übersichtliche Liste aller verfügbaren Blockgeräte kann der Befehl `lsblk` verwendet werden.
Hier ein Beispiel-Output:

```shellsession
$ lsblk
NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
sda       8:0    0 19.1G  0 disk
├─sda1    8:1    0 18.8G  0 part /
├─sda2    8:14   0    1M  0 part
└─sda3    8:15   0  256M  0 part /boot/efi
sdb       8:16   0   10G  0 disk
sdc       8:32   0   10G  0 disk
```

> Der Output zeigt Festplatte 1 (`sda`) mit drei Partitionen (`sda1`, `sda2`, `sda3`), Festplatte 2 (`sdb`) ohne Partitionen und Festplatte 3 (`sdc`) ebenfalls ohne Partitionen. 

**Hinweis**:
Für ein Software RAID, muss nicht die gesamte Festplatte dem RAID hinzugefügt werden. Es reichen einzelne Partitionen.

Für eine Liste mit genaueren Informationen der Partitionen kann `fdisk -l` verwendet werden.

In den folgenden Schritten wird erklärt, wie man `sdb` und `sdc` formatiert, jeweils eine Partition erstellt (`sdb1` und `sdc1`) und diese Partitionen als RAID-Partitionen markiert. Anschließend wird erklärt, wie man mit den neuen Partitionen `sdb1` und `sdc1` einen RAID-Verbund erstellt.

## Schritt 2 - Erstellen eines Software RAIDs

### Schritt 2.1 - Vorbereiten der Festplatten

Zunächst müssen die Festplatten entsprechend formatiert werden.

In dem Beispiel-Output von `lsblk` oben, besitzen die Festplatten `sdb` und `sdc` noch keine Partitionen. Auf beiden Festplatten muss daher:

* Jeweils eine Partitionstabelle erstellt werden
* Jeweils eine Partition erstellt werden
* Die neuen Partitionen als RAID-Partitionen markieren

-------------

> **Hinweis:** Beim Ausführen dieser Schritte gehen alle Daten auf den Festplatten verloren. Diese Schritte sollten also nur auf leeren Festplatten ausgeführt werden.

* **Partitionstabelle erstellen**<br>
  Auf beiden Festplatten eine neue, leere Partitionstabelle erstellen:
  * Für Festplatten größer als 2 TB oder PCs mit UEFI:
    ```bash
    sudo parted /dev/sdb mklabel gpt
    sudo parted /dev/sdc mklabel gpt
    ```
  * Für Festplatten kleiner als 2 TB und BIOS:
    ```bash
    sudo parted /dev/sdb mklabel msdos
    sudo parted /dev/sdc mklabel msdos
    ```

<br>

* **Partition erstellen**<br>
  Auf beiden Festplatten, eine Partition anlegen:
  ```bash
  sudo parted -a optimal -- /dev/sdb mkpart primary 2048s -8192s
  sudo parted -a optimal -- /dev/sdc mkpart primary 2048s -8192s
  ```
  Möchte man die gesamte Platte nutzen, gibt man statt `2048s -8192s` einfach `0% 100%` an.
  
  > **Hinweis**:
  > Es werden bewusst 8192 Sektoren am Ende der Festplatte ungenutzt gelassen, um für Ausfälle gewappnet zu sein. Es ermöglicht durch den freigelassenen Platz auch Laufwerke als Ersatz zu nehmen, die einige Sektoren weniger haben.

  Mit `lsblk` kann jetzt geprüft werden ob die Partitionen erfolgreich erstellt wurden:
  ```bash
  NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
  [...]
  sdb       8:16   0   10G  0 disk
  └─sdb1    8:17   0   10G  0 part
  sdc       8:32   0   10G  0 disk
  └─sdc1    8:33   0   10G  0 part
  ```

<br>

* **Neue Partitionen als RAID-Partition markieren**<br>
  Die neu angelegten Partitionen als RAID-Partitionen markieren:
  ```bash
  sudo parted /dev/sdb set 1 raid on
  sudo parted /dev/sdc set 1 raid on
  ```

### Schritt 2.2 - Anlegen des Software RAIDs

Unter Linux ist `mdadm` das Hauptwerkzeug. Es bildet die Schnittstelle zu den RAID-Funktionen des Kernels.

RAID kann mit einem Befehl angelegt werden, dabei muss das RAID-Level bestimmt und die Partitionen angegeben werden:

* **RAID 1**<br>
  > RAID: `md0`<br>
  > Devices: `sdb1`, `sdc1`
  
  ```bash
  sudo mdadm --create /dev/md0 --auto md --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1
  ```

* **RAID 5**<br>
  > RAID: `md0`<br>
  > Devices: `sdb1`, `sdc1`, `sdd1`, `sde1`
  
  ```bash
  sudo mdadm --create /dev/md0 --auto md --level=5 --raid-devices=4 /dev/sdb1 /dev/sdc1 /dev/sdd1 /dev/sde1
  ```

Die Parameter im Einzelnen:

| Parameter                 | Beschreibung                                                   |
| ------------------------- | -------------------------------------------------------------- |
| `--create /dev/md0`       | Erzeugt einen neuen Endpoint mit dem Namen "md0". Falls bereits Endpoints mit demselben Name vorhanden sind, muss ein anderer freier Name gewählt werden (md1,md2, etc.) |
| `--auto md`               | Erzeugt einen "klassischen" Endpoint ohne Vor-Partitionierung. |
| `--level=`                | Die Art des RAID-Levels.                                       |
| `--raid-devices`          | Die Anzahl der Einzelgeräte, aus denen das RAID bestehen soll. |
| `/dev/sde1 /dev/sde2 ...` | Die einzelnen Geräte, die zusammengefasst werden sollen. Die Reihenfolge der Bezeichner, bzw. idealerweise die der entsprechenden physischen Geräte sollte man sich aufschreiben, falls im Notfall das RAID von Hand neu zusammengesetzt werden muss. |

-----------

Das neu erstellte Blockgerät `mdX` kann sofort benutzt werden und das System darf auch währenddessen heruntergefahren oder neu gestartet werden. In diesem Beispiel heißt das neue Blockgerät `md0`.

  ```bash
  $ lsblk
  NAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
  [...]
  sdb       8:16   0   10G  0 disk
  └─sdb1    8:17   0   10G  0 part
    └─md0   9:0    0   10G  0 raid1
  sdc       8:32   0   10G  0 disk
  └─sdc1    8:33   0   10G  0 part
    └─md0   9:0    0   10G  0 raid1
  ```

Abfragen des aktuellen Status der RAID-Erstellung:

```bash
watch cat /proc/mdstat
```

Beispiel-Output:

```shell
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid1 sdc1[1] sdb1[0]
      10471424 blocks super 1.2 [2/2] [UU]
      [===============>.....]  resync = 75.5% (7907008/10471424) finish=0.3min speed=112850K/sec
```

-----------

Nun da der RAID-Verbund erstellt wurde, kann dieser formatiert und eingehängt werden.

* Formatieren des neuerstellten RAIDs:
  ```bash
  sudo mkfs.ext4 /dev/md0
  ```

<br>

* Einbinden des RAIDs:
  ```bash
  sudo mkdir /mnt/<your-mount-point>
  sudo mount /dev/md0 /mnt/<your-mount-point>
  ```
  `<your-mount-point>` kann mit einem beliebigen Ordnernamen ersetzt werden. Dieser Ordner dient als Einhängepunkt fürs RAID. Das heißt alle Dateien, die in diesem Ordner abgelegt werden, werden im RAID `md0` gespeichert.

<br>

* Automatisches Erstellen des RAIDs:<br>
  Damit RAID nach einem Reboot automatisch wieder erstellt wird, muss eine entsprechende Zeile in der `mdadm.conf`-Datei eingetragen werden.
  ```bash
  sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf
  sudo update-initramfs -u
  ```

<br>

* Automatisches Einbinden des RAIDs:<br>
  Damit RAID nach einem Reboot automatisch eingebunden wird, muss eine entsprechende Zeile in der `/etc/fstab`-Datei eingetragen werden.
  
  Namen wie `mdX` können sich verändern, daher ist es immer besser in der `fstab`-Datei die UUID anzugeben. Diese bleibt immer gleich.

  * **UUID herausfinden**<br>
    Über `lsblk` kann man sich den Namen des RAID-Blockgerätes anzeigen lassen:
    ```bash
    sdb       8:16   0   10G  0 disk
    └─sdb1    8:17   0   10G  0 part
      └─md0   9:0    0   10G  0 raid1 /mnt/<your-mount-point>
    sdc       8:32   0   10G  0 disk
    └─sdc1    8:33   0   10G  0 part
      └─md0   9:0    0   10G  0 raid1 /mnt/<your-mount-point>
    ```
    In diesem Beispiel ist der RAID-Name `md0`. Ersetze `md0` im folgenden Befehl mit dem Namen von deinem eigenen Blockgerät.    
    ```bash
    sudo blkid | grep md0
    ```
    Im Output sollte die UUID angegeben sein. Diese kann jetzt kopiert werden.
  
  * `fstab`**-Eintrag hinzufügen**
    ```bash
    sudo nano /etc/fstab
    ```
    Folgende Informationen müssen angegeben werden:
    ```shell
    <device/UUID> <mount-point> <file-system> <mount-options> <dump> <pass>
    ```
    Der Eintrag sollte dann so aussehen und ganz unten als neue Zeile ergänzt werden:
    ```shell
    UUID=<your-UUID>   /mnt/<your-mount-point>   ext4   defaults   0 2
    ```
    
    Nachdem die Zeile ergänzt wurde, können die Änderungen gespeichert werden. 

### Schritt 2.3 - Anlegen einer Hotspare-Festplatte (Optional)

Bei Hotspare Festplatten/Partitionen handelt es sich um Festplatten/Partitionen welche im Normalfall nicht verwendet werden. Diese kommen zum Einsatz wenn eine der aktiven Festplatten/Partitionen des RAID-Verbundes einen Fehler aufweist oder defekt ist. Wenn in einem Software-Raid keine Hotspare-Platte definiert ist, muss der Rebuild eines defekten RAIDs manuell gestartet werden. Ist eine Hotspare vorhanden wird automatisch mit dem Rebuild begonnen. Eine Hotspare-Festplatte kann mit `mdadm --add` hinzugefügt werden.

|                | Ohne Hotspare | Mit Hotspare |
| -------------- | ------------- | ------------ |
| RAID-Level:    | raid1         | raid1        |
| Raid Devices:  | 2             | 2            |
| Total Devices  | 2             | 3            |
| Active Devices | 2             | 2            |
| Spare Devices  | 0             | 1            |

> Diese Informationen kann man sich mit `sudo mdadm --detail /dev/md0` anzeigen lassen.

<br>

* **Hotspare festlegen**<br>
  > RAID: `md0`<br>
  > Devices: `sdb1`, `sdc1`<br>
  > Hotspare: `sdd1`
  
  In diesem Beispiel soll `sdd1` als Hotspare genutzt werden. Bevor die neue Festplatte dem RAID hinzugefügt wird, muss diese genau wie die Festplatten `sdb` und `sdc` zunächst formatiert werden (siehe "Schritt 2.1"). Anschließend kann der Befehl zum Hinzufügen des Hotspare ausgeführt werden:
  ```bash
  sudo mdadm --add /dev/md0 /dev/sdd1
  ```

<br>

* **Hotspare verwenden**<br>
  Wenn `sdc1` zum Beispiel vom System entfernt wird, beginnt automatisch ein Rebuild und RAID würde anschließend so aussehen:
  > RAID: `md0`<br>
  > Devices: `sdb1`, `sdd1`<br>
  > Defekt: `sdc1`

<br>

* **Neues Hotspare festlegen**<br>
  Wenn `sdc1` wieder einsatzbereit ist, wird es dem RAID nicht automatisch wieder hinzugefügt. Es kann aber manuell als neues Hotspare festgelegt werden.
  ```bash
  sudo mdadm --add /dev/md0 /dev/sdc1
  ```
  > RAID: `md0`<br>
  > Devices: `sdb1`, `sdd1`<br>
  > Hotspare: `sdc1`

## Schritt 3 - Auflösen eines Software RAIDs

Um ein Software RAID aufzulösen, müssen folgende Schritte ausgeführt werden:

**Beispiel**<br>
RAID: `md0`<br>
Devices: `sdb1`, `sdc1`<br>

1. **Stoppen des RAIDs**
   ```bash
   sudo umount /dev/md0
   sudo mdadm --stop /dev/md0
   ```

<br>

2. **Automatische Mount-Einträge entfernen** (z.B. `/etc/fstab`)
   ```bash
   nano /etc/fstab
   ```
   In der Datei, muss nun der entsprechende Mount-Eintrag entfernt werden. Im Beispiel aus Schritt 2 sah der Eintrag so aus:
   ```bash
   UUID=<your-UUID>   /mnt/<your-mount-point>   ext4   defaults   0 2
   ```
   Anschließend kann initramfs aktualisiert werden:
   ```bash
   sudo update-initramfs -u
   ```

<br>

3. **RAID Eintrag in der `mdadm.conf` löschen**<br>
   ```bash
   nano /etc/mdadm/mdadm.conf
   ```   
   In der Datei, muss nun der entsprechende Eintrag entfernt werden. Dieser sollte in etwa so aussehen:
   ```bash
   ARRAY /dev/md0 metadata=1.2 name=<your-server-name>:1 UUID=<your-UUID>
   ```

<br>

4. **Superblock der verwendeten Partitionen löschen**
   ```bash
   sudo mdadm --zero-superblock /dev/sdb1 /dev/sdc1
   ```

<br>

5. **RAID flag deaktivieren**
   ```bash
   sudo parted /dev/sdb set 1 raid off
   sudo parted /dev/sdc set 1 raid off
   ```

## Schritt 4 - Verwaltung eines Software RAIDs

### Schritt 4.1 - RAID Status ermitteln

Eine kurze Auflistung aller RAIDs im System erhält man mit dem Output der Datei `/proc/mdstat`.

```shellsession
$ cat /proc/mdstat
Personalities : [raid1] [linear] [multipath] [raid0] [raid6] [raid5] [raid4] [raid10]
md0 : active raid1 sdb1[1] sdc1[0]
       8380416 blocks super 1.2 [2/2] [UU]

md2 : active raid1 sdb3[1] sdc3[0]
       536739840 blocks super 1.2 [2/2] [UU]
       bitmap: 3/4 pages [12KB], 65536KB chunk

md1 : active raid1 sdb2[1] sdc2[0]
       1047552 blocks super 1.2 [2/2] [UU]

unused devices: <none>
```

Genauere Informationen erhält man mit diesem Befehl:

```bash
sudo mdadm --detail /dev/md2
```

<details>

<summary>Hier klicken für ein Beispiel-Output</summary>

```shell
/dev/md2:
           Version : 1.2
     Creation Time : Fri Feb 22 17:19:37 2019
        Raid Level : raid1
        Array Size : 536739840 (511.88 GiB 549.62 GB)
     Used Dev Size : 536739840 (511.88 GiB 549.62 GB)
      Raid Devices : 2
     Total Devices : 2
       Persistence : Superblock is persistent

     Intent Bitmap : Internal

       Update Time : Sun May 26 13:49:02 2019
             State : clean
    Active Devices : 2
   Working Devices : 2
    Failed Devices : 0
     Spare Devices : 0

Consistency Policy : bitmap

              Name : rescue:2
              UUID : c76e5446:f3c41fbc:0b62ca86:803a7e88
            Events : 2170

    Number   Major   Minor   RaidDevice State
       0       8        3        0      active sync   /dev/sdc3
       1       8       19        1      active sync   /dev/sdb3
```

</details>

### Schritt 4.2 - Defekte Festplatte tauschen

In den folgenden Befehlen wird dieses Beispiel verwendet:

RAID: `md0`<br>
Devices: `sdb1`, `sdc1`<br>
Defekt: `sdb1`<br>
Ersatz: `sdd1`

In den folgenden Schritten wird die fehlerhafte Partition `sdb1` aus dem RAID entfernt, die Festplatte wird ausgetauscht und anschließend wird die funktionierende Partition `sdd1` dem RAID hinzugefügt.

* **Defekte Festplatte aus RAID entfernen**<br>
  Zunächst muss die defekte Festplatte als "failed" markiert und aus dem RAID entfernt werden:
  ```bash
  sudo mdadm --manage /dev/md0 --fail /dev/sdb1
  sudo mdadm --manage /dev/md0 --remove /dev/sdb1
  ```

  Die defekte Festplatte kann jetzt gegen eine neue Festplatte ausgetauscht werden. Anschließend kann die neue Festplatte partitioniert und dem RAID hinzugefügt werden.

<br>

* **Neue Festplatte partitionieren**<br>
  Wenn keine Hotspare-Festplatte zur Verfügung steht, muss eine neue Festplatte partitioniert werden. Dabei ist wichtig, dass die neue Festplatte dieselbe Partitionierung wie die defekte Festplatte aufweist!
  
  Um die neue Festplatte zu partitionieren, genügt es die Partitionstabelle von einer bestehenden Festplatte zu kopieren.
  
  * Für MBR-partitionierte Festplatten:
    ```bash
    sudo sfdisk --dump /dev/sdc > sdc_parttable_mbr.bak # Erstellt ein Backup der Partitionstabelle
    sudo sfdisk -d /dev/sdc | sudo sfdisk /dev/sdd      # Kopiert die Partitionstabelle von sdc zu sdd
    ```

  * Für GPT Partitionierte Festplatten:
    ```bash
    sgdisk --backup=sdc_parttable_gpt.bak /dev/sdc      # Erstellt ein Backup der Partitionstabelle
    sgdisk --load-backup=sdc_parttable_gpt.bak /dev/sdd # Kopiert das erstellte Backup der Partitionstabelle auf sdd
    ```

<br>

* **Funktionierende Festplatte dem RAID-Verbund hinzufügen**<br>
  Wenn die neue Festplatte korrekt partitioniert ist, kann die Partition dem RAID-Verbund wieder hinzugefügt werden:
  ```bash
  sudo mdadm --manage /dev/md0 -a /dev/sdd1
  ```

<br>

* **Wiederherstellungsprozess**<br>
  Der Wiederherstellungsprozess sollte automatisch starten. Der Fortschritt kann wieder über den Befehl `watch cat /proc/mdstat` überwacht werden.

  Sobald der Rebuild des RAIDs abgeschlossen ist, kann mit `sudo mdadm --detail /dev/md0` geprüft werden ob es nun wieder 2 `Active Devices` gibt.

> **Hinweis**: Sollte das System auf dem RAID selbst liegen, ist es notwendig den Bootloader auf der entsprechenden Festplatte zu installieren. Dies geschieht mit dem folgenden Befehl:
> ```bash
> update-grub
> grub-install /dev/sda
> ```

### Schritt 4.3 - RAID erweitern

> Die Erweiterung eines RAID-Verbunds sollte immer sorgfältig geplant werden. Es besteht immer das Risiko, dass Daten verlogen gehen könnten.

Es können nur RAIDs mit Level 1, 4, 5 und 6 erweitert werden.

Folgende Schritte sind notwendig:

* Zusätzliche Festplatte/Partition dem RAID-Verbund hinzufügen
* RAID-Level anpassen
* Größe des Dateisystems anpassen

--------------

In den folgenden Beispiel-Befehlen wird dieses Beispiel verwendet:

|             | Vorher                          | Nachher                                         |
| ----------- | ------------------------------- | ----------------------------------------------- |
| RAID-Level: | 1                               | 5                                               |
| RAID:       | <kbd>md0</kbd>                  | <kbd>md0</kbd>                                  |
| Devices:    | <kbd>sdb1</kbd> <kbd>sdc1</kbd> | <kbd>sdb1</kbd> <kbd>sdc1</kbd> <kbd>sdd1</kbd> |

> Mit `sudo mdadm --detail /dev/md0` kann man sich die aktuellen Informationen anzeigen lassen.

* **Zusätzliche Festplatte dem RAID-Verbund hinzufügen**<br>
  Die neue Partition muss zunächst als Hotspare hinzugefügt werden:
  ```bash
  sudo mdadm /dev/md0 --add /dev/sdd1
  ```
  > Mit `sudo mdadm --detail /dev/md0` kann geprüft werden, ob `sdd1` nun als Hotspare verfügbar ist.

<br>

* **RAID-Level anpassen**<br>
  Jetzt kann der RAID-Verbund um das neue Laufwerk erweitert werden:
  ```bash
  sudo mdadm --grow --raid-devices=3 --level=5 /dev/md0 --backup-file=/root/md0.bak
  ```
  
  > **Hinweis**:
  > In der mittels `--backup-file` angegebenen Datei werden kritische Bereiche gesichert (typischerweise einige wenige MiB). Falls das System während der Erweiterung abstürzt, kann die Erweiterung später mittels folgendem Befehl fortgesetzt werden:
  > ```bash
  > sudo mdadm /dev/md0 --continue --backup-file=/tmp/md0.bak
  > ```
  > Die Sicherungsdatei darf nicht auf dem zu erweiternden RAID liegen! Die Verwendung von `backup-file` ist nicht zwingend notwendig, wird aber dringend empfohlen.

<br>

* **`mdadm.conf`-Eintrag anpassen**<br>
  Falls der Eintrag in der `mdadm.conf`-Datei das RAID-Level und die Anzahl der Devices enthält, müssen diese Angaben entsprechend angepasst werden. Mit folgendem Befehl kann man den Eintrag bearbeiten:
  ```bash
  nano /etc/mdadm/mdadm.conf
  ```
  * Wenn der Eintrag keine Angaben zu RAID-Level und Anzahl der Devices enthält, muss nichts geändert werden. Beispiel:
    ```bash
    ARRAY /dev/md0 metadata=1.2 name=<your-server-name>:0 UUID=<your-UUID>
    ```
  * Wenn der Eintrag RAID-Level (`level=1`) und Anzahl der Devices (`num-devices=2`) enthält, müssen diese angepasst werden. Beispiel:
    ```bash
    ARRAY /dev/md0 level=5 num-devices=3 metadata=1.2 name=<your-server-name>:0 UUID=<your-UUID>
    ```

<br>

* **Größe des Dateisystems anpassen**<br>
  Damit der neu entstandene Speicherplatz genutzt werden kann, muss jetzt noch das Dateisystem erweitert werden. 
  * Mit folgendem Befehl kann man sich die aktuelle Größe anzeigen lassen:
    ```bash
    df -h /mnt/<your-mount-point>
    ```
  * Die Erweiterung findet mit folgenden Befehlen statt:
    ```bash
    sudo umount /dev/md0 /mnt/<your-mount-point> # Das Dateisystem aushängen
    sudo fsck.ext4 -f /dev/md0                   # Die Prüfung erzwingen, selbst wenn vor Kurzem geprüft wurde
    sudo resize2fs /dev/md0                      # Das Dateisystem auf Maximalgröße erweitern
    sudo mount /dev/md0 /mnt/<your-mount-point>  # Das Dateisystem wieder einhängen
    ```
    > Wenn eine Fehlermeldung wie `target is busy` angezeigt wird, laufen eventuell noch Prozesse. Mit `lsof +D /mnt/<your-mount-point>` kann man sich alle Prozesse listen lassen, die diesen Ordner verwenden. Wenn der Prozess nicht wichtig ist, kann dieser mit `kill -9 <PID>` gestoppt werden.
  * Zum Vergleich kann man sich abschließend noch die neue Größe anzeigen lassen:
    ```bash
    df -h /mnt/<your-mount-point>
    ```

### Schritt 4.4 - RAID überwachen

Um das RAID zu überwachen, kann dieser Eintrag als Crontab (`sudo crontab -e`) hinterlegt werden:

```bash
0 0 * * * /usr/share/mdadm/checkarray --cron --all --quiet >/dev/null 2>&1 # Läuft jeden Tag um 00:00 Uhr
```

## Ergebnis

In diesem Beitrag wurde erklärt, wie man ein passendes RAID-Level für sein Vorhaben auswählt und dieses dann entsprechend auf Linux Systemen mithilfe von `mdadm` konfiguriert. Des weiteren wurde auf administrative Tätigkeiten eingegangen, wie zum Beispiel das Erweitern eines RAIDs oder das Tauschen defekter Festplatten.

##### License: MIT

<!---

Contributors's Certificate of Origin

By making a contribution to this project, I certify that:

(a) The contribution was created in whole or in part by me and I have
    the right to submit it under the license indicated in the file; or

(b) The contribution is based upon previous work that, to the best of my
    knowledge, is covered under an appropriate license and I have the
    right under that license to submit that work with modifications,
    whether created in whole or in part by me, under the same license
    (unless I am permitted to submit under a different license), as
    indicated in the file; or

(c) The contribution was provided directly to me by some other person
    who certified (a), (b) or (c) and I have not modified it.

(d) I understand and agree that this project and the contribution are
    public and that a record of the contribution (including all personal
    information I submit with it, including my sign-off) is maintained
    indefinitely and may be redistributed consistent with this project
    or the license(s) involved.

Signed-off-by: markus@omg-network.de

-->
